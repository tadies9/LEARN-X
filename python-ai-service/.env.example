# Application Settings
APP_NAME="LEARN-X Python AI Service"
APP_VERSION="1.0.0"
ENVIRONMENT=development
DEBUG=true

# API Configuration
API_PREFIX=/api/v1
CORS_ORIGINS=http://localhost:3000,http://localhost:3001,http://localhost:8080
INTERNAL_API_KEY=your-internal-api-key

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/learnx
DATABASE_POOL_SIZE=10
DATABASE_MAX_OVERFLOW=20

# Queue Configuration
PGMQ_POLL_INTERVAL=5000
PGMQ_VISIBILITY_TIMEOUT=300  # 5 minutes for file processing
PGMQ_BATCH_SIZE=5  # Smaller batch for file processing
PGMQ_MAX_RETRIES=3

# OpenAI
OPENAI_API_KEY=sk-your-openai-api-key
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OPENAI_EMBEDDING_DIMENSIONS=1536
OPENAI_MAX_BATCH_SIZE=50

# Local AI Models (Future)
ENABLE_LOCAL_MODELS=false
LOCAL_LLM_PATH=/models/llama-2-7b
LOCAL_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Document Processing
MAX_FILE_SIZE_MB=50
DEFAULT_CHUNK_SIZE=1500
MIN_CHUNK_SIZE=200
CHUNK_OVERLAP=100

# Performance
WORKER_COUNT=4
MAX_CONCURRENT_JOBS=10
REQUEST_TIMEOUT=300

# Monitoring
LOG_LEVEL=INFO
SENTRY_DSN=
ENABLE_METRICS=true
METRICS_PORT=9090