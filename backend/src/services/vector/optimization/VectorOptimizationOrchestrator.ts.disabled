import { VectorSearchAdapter } from '../VectorSearchAdapter';
import { VectorPerformanceMonitor } from '../monitoring/VectorPerformanceMonitor';
import { VectorSearchCache } from './VectorSearchCache';
import { VectorQuantization, createOptimalQuantizer } from './VectorQuantization';
import { HybridSearchOptimizer } from './HybridSearchOptimizer';
import { VectorSearchResult, VectorSearchOptions } from '../interfaces/IVectorStore';
import { logger } from '../../../utils/logger';

// Interface for embedding services
interface IEmbeddingService {
  generateEmbedding(text: string, userId?: string): Promise<number[]>;
  generateBatchEmbeddings?(chunks: Array<{ id: string; content: string }>, userId?: string): Promise<Array<{ chunkId: string; embedding: number[] }>>;
}

export interface OptimizationConfig {
  enableCaching: boolean;
  enableQuantization: boolean;
  enableHybridSearch: boolean;
  enableMonitoring: boolean;
  cacheConfig?: {
    ttlSeconds: number;
    maxResults: number;
  };
  quantizationConfig?: {
    compressionRatio: number;
    minAccuracy: number;
  };
  hybridConfig?: {
    vectorWeight: number;
    keywordWeight: number;
  };
}

export interface OptimizedSearchResult {
  results: VectorSearchResult[];
  performance: {
    totalLatencyMs: number;
    cacheHit: boolean;
    quantizationUsed: boolean;
    hybridSearchUsed: boolean;
  };
  optimizations: {
    applied: string[];
    suggestions: string[];
  };
}

export class VectorOptimizationOrchestrator {
  private adapter: VectorSearchAdapter;
  private monitor: VectorPerformanceMonitor;
  private cache: VectorSearchCache;
  private quantizer?: VectorQuantization;
  private hybridOptimizer: HybridSearchOptimizer;
  private embeddingService: IEmbeddingService;
  private config: OptimizationConfig;

  constructor(
    embeddingService: IEmbeddingService,
    config: Partial<OptimizationConfig> = {}
  ) {
    this.embeddingService = embeddingService;
    this.config = {
      enableCaching: true,
      enableQuantization: false, // Disabled by default until fully tested
      enableHybridSearch: true,
      enableMonitoring: true,
      cacheConfig: {
        ttlSeconds: 3600,
        maxResults: 1000,
      },
      quantizationConfig: {
        compressionRatio: 4,
        minAccuracy: 0.95,
      },
      hybridConfig: {
        vectorWeight: 0.7,
        keywordWeight: 0.3,
      },
      ...config,
    };

    this.adapter = new VectorSearchAdapter(embeddingService);
    this.monitor = new VectorPerformanceMonitor({
      provider: 'pgvector',
      enableDetailedLogging: this.config.enableMonitoring,
    });
    this.cache = new VectorSearchCache(this.config.cacheConfig);
    this.hybridOptimizer = new HybridSearchOptimizer(this.config.hybridConfig);

    // Initialize quantization if enabled
    if (this.config.enableQuantization) {
      this.quantizer = createOptimalQuantizer({
        targetCompressionRatio: this.config.quantizationConfig!.compressionRatio,
        minAccuracy: this.config.quantizationConfig!.minAccuracy,
        vectorDimensions: 1536,
      });
    }
  }

  /**
   * Perform optimized search with all available optimizations
   */
  async optimizedSearch(
    query: string,
    options: VectorSearchOptions = {},
    forceBypassCache: boolean = false
  ): Promise<OptimizedSearchResult> {
    const startTime = Date.now();
    const appliedOptimizations: string[] = [];
    const suggestions: string[] = [];
    let results: VectorSearchResult[] = [];
    let cacheHit = false;
    let quantizationUsed = false;
    let hybridSearchUsed = false;

    try {
      // Generate embedding for the query
      const queryVector = await this.embeddingService.generateEmbedding(query);
      
      // Try cache first (if enabled and not bypassed)
      if (this.config.enableCaching && !forceBypassCache) {
        const cachedResults = await this.cache.get(queryVector, options, 'pgvector');
        
        if (cachedResults) {
          cacheHit = true;
          appliedOptimizations.push('cache');
          
          logger.debug('[VectorOptimizer] Cache hit for query');
          
          return {
            results: cachedResults,
            performance: {
              totalLatencyMs: Date.now() - startTime,
              cacheHit: true,
              quantizationUsed: false,
              hybridSearchUsed: false,
            },
            optimizations: {
              applied: appliedOptimizations,
              suggestions: [],
            },
          };
        }
      }

      // Determine search strategy based on query analysis
      if (this.config.enableHybridSearch) {
        const queryAnalysis = this.hybridOptimizer.analyzeQuery(query);
        
        if (queryAnalysis.queryType === 'hybrid' || queryAnalysis.hasKeywords) {
          // Use hybrid search
          hybridSearchUsed = true;
          appliedOptimizations.push('hybrid_search');
          
          results = await this.performHybridSearch(query, queryVector, options);
          
          // Get optimization suggestions
          suggestions.push(...this.hybridOptimizer.getOptimizationSuggestions(query, results as any));
        } else {
          // Use pure vector search
          results = await this.performVectorSearch(queryVector, options);
        }
      } else {
        // Use pure vector search
        results = await this.performVectorSearch(queryVector, options);
      }

      // Apply quantization if enabled and beneficial
      if (this.config.enableQuantization && this.quantizer) {
        const shouldQuantize = await this.shouldUseQuantization(options);
        
        if (shouldQuantize) {
          quantizationUsed = true;
          appliedOptimizations.push('quantization');
          
          // Note: Quantization would be applied during indexing, not search
          suggestions.push('Consider enabling quantization for faster searches at scale');
        }
      }

      // Cache results if caching is enabled
      if (this.config.enableCaching && results.length > 0) {
        await this.cache.set(queryVector, options, 'pgvector', results);
        appliedOptimizations.push('result_caching');
      }

      // Generate additional optimization suggestions
      suggestions.push(...this.generateOptimizationSuggestions(results, options));

      const totalLatency = Date.now() - startTime;

      // Log performance metrics if monitoring is enabled
      if (this.config.enableMonitoring) {
        await this.monitor.monitorSearch(
          async () => ({ results }),
          {
            query,
            resultCount: results.length,
            appliedOptimizations,
            latencyMs: totalLatency,
          }
        );
      }

      return {
        results,
        performance: {
          totalLatencyMs: totalLatency,
          cacheHit,
          quantizationUsed,
          hybridSearchUsed,
        },
        optimizations: {
          applied: appliedOptimizations,
          suggestions,
        },
      };

    } catch (error) {
      logger.error('[VectorOptimizer] Optimized search failed:', error);
      throw error;
    }
  }

  /**
   * Perform vector search with monitoring
   */
  private async performVectorSearch(
    _queryVector: number[],
    options: VectorSearchOptions
  ): Promise<VectorSearchResult[]> {
    if (this.config.enableMonitoring) {
      return this.monitor.monitorSearch(async () => {
        const results = await this.adapter.searchSimilarChunks('', {
          ...options,
          // Custom adapter options would go here
        });
        
        return results.map(result => ({
          id: result.chunkId,
          score: result.similarity,
          metadata: result.metadata || { fileId: result.fileId },
          content: result.content,
        }));
      });
    } else {
      const results = await this.adapter.searchSimilarChunks('', options);
      
      return results.map(result => ({
        id: result.chunkId,
        score: result.similarity,
        metadata: result.metadata || { fileId: result.fileId },
        content: result.content,
      }));
    }
  }

  /**
   * Perform hybrid search with monitoring
   */
  private async performHybridSearch(
    query: string,
    queryVector: number[],
    options: VectorSearchOptions
  ): Promise<VectorSearchResult[]> {
    if (this.config.enableMonitoring) {
      return this.monitor.monitorSearch(async () => {
        return this.hybridOptimizer.optimizedHybridSearch(query, queryVector, options);
      });
    } else {
      return this.hybridOptimizer.optimizedHybridSearch(query, queryVector, options);
    }
  }

  /**
   * Determine if quantization should be used for this search
   */
  private async shouldUseQuantization(options: VectorSearchOptions): Promise<boolean> {
    // Quantization is beneficial for:
    // 1. Large-scale searches (high topK)
    // 2. When memory is constrained
    // 3. When slight accuracy loss is acceptable

    const topK = options.topK || 10;
    
    // Use quantization for large result sets
    if (topK > 100) {
      return true;
    }

    // Check if we have memory pressure
    const memoryUsage = process.memoryUsage();
    const memoryPressure = memoryUsage.heapUsed / memoryUsage.heapTotal;
    
    if (memoryPressure > 0.8) {
      return true;
    }

    return false;
  }

  /**
   * Generate optimization suggestions based on search results
   */
  private generateOptimizationSuggestions(
    results: VectorSearchResult[],
    options: VectorSearchOptions
  ): string[] {
    const suggestions: string[] = [];

    // Analyze result quality
    const avgScore = results.reduce((sum, r) => sum + r.score, 0) / results.length;
    
    if (avgScore < 0.5) {
      suggestions.push('Low similarity scores detected - consider adjusting similarity threshold or improving query');
    }

    if (results.length === 0) {
      suggestions.push('No results found - consider lowering similarity threshold or using hybrid search');
    }

    if (results.length < (options.topK || 10) / 2) {
      suggestions.push('Few results returned - consider expanding search scope or using keyword expansion');
    }

    // Performance suggestions
    if (options.topK && options.topK > 50) {
      suggestions.push('Large result set requested - consider using pagination or caching for better performance');
    }

    // Cache suggestions
    if (this.config.enableCaching) {
      const cacheMetrics = this.cache.getMetrics();
      if (cacheMetrics.hitRate < 20) {
        suggestions.push('Low cache hit rate - consider query optimization or cache warming');
      }
    }

    return suggestions;
  }

  /**
   * Index chunks with optimization
   */
  async optimizedIndexing(
    chunks: Array<{
      id: string;
      fileId: string;
      content: string;
      metadata?: Record<string, any>;
    }>,
    userId?: string
  ): Promise<{
    success: boolean;
    optimizations: string[];
    performance: {
      indexingLatencyMs: number;
      quantizationSavings?: number;
    };
  }> {
    const startTime = Date.now();
    const appliedOptimizations: string[] = [];

    try {
      // Apply quantization if enabled
      if (this.config.enableQuantization && this.quantizer) {
        appliedOptimizations.push('quantization');
        
        // Generate embeddings
        const embeddings = await this.embeddingService.generateEmbedding(
          chunks.map(c => c.content),
          userId
        );

        // Quantize embeddings
        const quantizedEmbeddings = this.quantizer.quantizeBatch(embeddings);
        
        // Calculate compression savings
        const originalSize = embeddings.length * embeddings[0].length * 4; // 4 bytes per float
        const quantizedSize = quantizedEmbeddings.reduce((sum, q) => sum + q.quantizedData.length, 0);
        const compressionRatio = originalSize / quantizedSize;

        logger.info('[VectorOptimizer] Quantization applied', {
          originalSizeMB: (originalSize / 1024 / 1024).toFixed(2),
          quantizedSizeMB: (quantizedSize / 1024 / 1024).toFixed(2),
          compressionRatio: compressionRatio.toFixed(2),
        });

        // Index with quantized embeddings (implementation would depend on storage format)
        // For now, we'll index normally and note the optimization
      }

      // Index chunks using the adapter
      if (this.config.enableMonitoring) {
        await this.monitor.monitorIndex(
          async () => {
            await this.adapter.indexChunks(chunks, userId);
            return { success: true };
          },
          chunks.length,
          1536
        );
      } else {
        await this.adapter.indexChunks(chunks, userId);
      }

      appliedOptimizations.push('batch_indexing');

      // Invalidate relevant cache entries
      if (this.config.enableCaching) {
        const fileIds = [...new Set(chunks.map(c => c.fileId))];
        for (const fileId of fileIds) {
          await this.cache.invalidate({ fileId });
        }
        appliedOptimizations.push('cache_invalidation');
      }

      return {
        success: true,
        optimizations: appliedOptimizations,
        performance: {
          indexingLatencyMs: Date.now() - startTime,
          quantizationSavings: this.config.enableQuantization ? 75 : undefined, // Estimated savings
        },
      };

    } catch (error) {
      logger.error('[VectorOptimizer] Optimized indexing failed:', error);
      throw error;
    }
  }

  /**
   * Get comprehensive performance report
   */
  async getPerformanceReport(): Promise<{
    cache: any;
    monitoring: any;
    optimizations: {
      quantizationEnabled: boolean;
      hybridSearchEnabled: boolean;
      cachingEnabled: boolean;
    };
    recommendations: string[];
  }> {
    const recommendations: string[] = [];

    // Get cache statistics
    const cacheStats = await this.cache.getDetailedStats();
    
    // Get monitoring report if enabled
    let monitoringReport = null;
    if (this.config.enableMonitoring) {
      monitoringReport = await this.monitor.generatePerformanceReport(60);
    }

    // Generate system-wide recommendations
    if (cacheStats.metrics.hitRate < 30) {
      recommendations.push('Cache hit rate is low - consider query optimization or cache pre-warming');
    }

    if (monitoringReport && monitoringReport.stats.search.avgLatencyMs > 300) {
      recommendations.push('Average search latency is high - consider index optimization or scaling');
    }

    if (!this.config.enableQuantization) {
      recommendations.push('Consider enabling quantization for memory savings and faster searches');
    }

    if (!this.config.enableHybridSearch) {
      recommendations.push('Consider enabling hybrid search for better query coverage');
    }

    return {
      cache: cacheStats,
      monitoring: monitoringReport,
      optimizations: {
        quantizationEnabled: this.config.enableQuantization,
        hybridSearchEnabled: this.config.enableHybridSearch,
        cachingEnabled: this.config.enableCaching,
      },
      recommendations,
    };
  }

  /**
   * Warm up optimizations (cache, etc.)
   */
  async warmup(popularQueries: string[]): Promise<void> {
    if (!this.config.enableCaching) {
      return;
    }

    logger.info('[VectorOptimizer] Starting optimization warmup');

    const warmupQueries = await Promise.all(
      popularQueries.map(async query => {
        const queryVector = await this.embeddingService.generateEmbedding(query);
        return {
          queryVector,
          options: { topK: 10, threshold: 0.7 },
          provider: 'pgvector' as const,
        };
      })
    );

    await this.cache.warmup(warmupQueries);
    
    logger.info('[VectorOptimizer] Optimization warmup completed');
  }

  /**
   * Update configuration
   */
  updateConfig(newConfig: Partial<OptimizationConfig>): void {
    this.config = { ...this.config, ...newConfig };

    // Reinitialize components if needed
    if (newConfig.quantizationConfig && this.config.enableQuantization) {
      this.quantizer = createOptimalQuantizer({
        targetCompressionRatio: this.config.quantizationConfig?.compressionRatio || 0.5,
        minAccuracy: this.config.quantizationConfig?.minAccuracy || 0.95,
        vectorDimensions: 1536,
      });
    }

    logger.info('[VectorOptimizer] Configuration updated', this.config);
  }

  /**
   * Cleanup resources
   */
  async cleanup(): Promise<void> {
    // No explicit cleanup needed for current implementation
    logger.info('[VectorOptimizer] Cleanup completed');
  }
}

// Export factory function for creating optimized instances
export function createOptimizedVectorService(
  embeddingService: IEmbeddingService,
  config?: Partial<OptimizationConfig>
): VectorOptimizationOrchestrator {
  return new VectorOptimizationOrchestrator(embeddingService, config);
}